# Projet de R√©gression Lin√©aire - Pr√©diction de Prix de Voitures

Ce projet impl√©mente un mod√®le de r√©gression lin√©aire pour pr√©dire le prix des voitures en fonction de leur kilom√©trage. Il est compos√© de deux parties principales : un module d'entra√Ænement du mod√®le et un module de pr√©diction.

## üìä Vue d'ensemble du projet

Le projet utilise la r√©gression lin√©aire, une technique d'apprentissage automatique fondamentale, pour √©tablir une relation lin√©aire entre :
- Variable ind√©pendante (X) : Kilom√©trage de la voiture
- Variable d√©pendante (y) : Prix de la voiture

## üîß Structure du Projet

Le projet est divis√© en deux scripts principaux :

### 1. Module d'Entra√Ænement (`training.py`)

Ce module impl√©mente l'algorithme de descente de gradient pour entra√Æner le mod√®le :

```python
def train_model():
    X, y = load_data()                    # Chargement des donn√©es
    X_norm, X_mean, X_std = normalize_data(X)  # Normalisation
    theta_norm, cost_history = gradient_descent(X_norm, y_norm, 500)  # Entra√Ænement
```

#### Fonctionnalit√©s cl√©s :
- Normalisation des donn√©es (z-score)
- Descente de gradient optimis√©e avec des op√©rations matricielles
- Calcul et suivi des m√©triques de performance (MSE, RMSE, R¬≤)
- Sauvegarde automatique des param√®tres du mod√®le

### 2. Module de Pr√©diction (`predict.py`)

Ce module permet d'utiliser le mod√®le entra√Æn√© pour faire des pr√©dictions :

```python
def ft_predict():
    theta0, theta1 = ft_load_params('model_params.txt')
    # Prix = theta0 + theta1 * kilom√©trage
```

#### Fonctionnalit√©s cl√©s :
- Interface interactive pour les pr√©dictions
- Validation robuste des entr√©es utilisateur
- Visualisation des pr√©dictions
- Gestion des erreurs compl√®te

## üéØ Caract√©ristiques Techniques Importantes

### Validation des Donn√©es
Le projet inclut une validation exhaustive des donn√©es :
- V√©rification des colonnes requises
- D√©tection des valeurs nulles
- Validation des valeurs n√©gatives
- V√©rification des formats de fichiers

### Normalisation
La normalisation z-score est utilis√©e pour standardiser les donn√©es :
```python
X_norm = (X - mean) / std
```
Cette √©tape est cruciale pour :
- Acc√©l√©rer la convergence de la descente de gradient
- Am√©liorer la stabilit√© num√©rique
- Rendre le mod√®le plus robuste

### Descente de Gradient
L'impl√©mentation utilise la descente de gradient par lots avec :
- Op√©rations matricielles optimis√©es avec NumPy
- Crit√®re de convergence automatique
- Suivi de l'historique des co√ªts

### Visualisations
Le projet inclut plusieurs visualisations :
- Donn√©es d'entra√Ænement et ligne de r√©gression
- Historique de la fonction co√ªt
- Points de pr√©diction individuels

## üìà M√©triques de Performance

Le mod√®le calcule plusieurs m√©triques pour √©valuer sa performance :
- MSE (Mean Squared Error)
- RMSE (Root Mean Squared Error)
- R¬≤ Score
- Pr√©cision du mod√®le bas√©e sur l'√©cart-type

## üöÄ Utilisation

### Entra√Ænement du mod√®le :
```bash
python training.py
```

### Faire des pr√©dictions :
```bash
python predict.py
```

## üõ† D√©pendances
- NumPy : Calculs matriciels
- Pandas : Manipulation des donn√©es
- Matplotlib : Visualisations

## üîç Points Techniques Notables

1. **Robustesse** :
   - Gestion extensive des erreurs
   - Validation des donn√©es en entr√©e
   - Limites raisonnables sur les pr√©dictions

2. **Performance** :
   - Utilisation d'op√©rations vectoris√©es
   - Crit√®re de convergence optimis√©
   - Normalisation des donn√©es

3. **Maintenabilit√©** :
   - Code modulaire
   - Documentation claire
   - Tests de validation int√©gr√©s

‚ö†Ô∏è Note

Vous l'avez remarqu√©, ce README a √©t√© g√©n√©r√© par Claude AI. Le contenu a cependant √©t√© totalement v√©rifi√© par moi-m√™me afin de correspondre parfaitement √† mon impl√©mentation. Enjoy üòä
